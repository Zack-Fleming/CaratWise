---
title: "CaratWiseModel"
author: "Zackery Fleming, Jake Compton, Cristian Castro"
date: "2023-10-26"
output:
  html_document:
    css: styles.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
![Diamond Dimensions](DiamondImage.jpg)


## Introduction

The goal of our project is to predict the price of diamonds within 80% to 90% accuracy of the true price.  The audience that is most interested in our work consists of the buyers and sellers of diamonds.  The dataset that we use in this project comes from Kaggle. We begin by exploring and analyzing the dataset.  We then move onto data wrangling, testing models, and finally our results.  We conclude with an explanation of our findings. 

## Explanation of the Diamond Dataset




## Importaing Libraries and Data

```{r}
library(tidyverse)  # data manipulation and wrangling
library(ggplot2)    # graphs and charts for data visualization
library(gridExtra)  # showing multiple plots next one another
library(reshape2)   # for reshaping matrices, for correlation matrix

# reading in data from csv file
diamonds_raw <- read_csv("diamonds.csv", col_names = TRUE, col_types = "ncccnnnnnn")
```


## Data Visualization

Now its a good time to look at the dataset, to see what we can expect. Charts and graphs is a great way to visually understand the dataset.

### Data Summary

Let's start with simply looking at the first few records, to get an idea of what we are looking at.
```{r}
head(diamonds_raw)
```


Now, let's look at a summary of the dataset, to see the ranges and medians of the columns, as well as if there are any missing/NULL values. 
```{r}
summary(diamonds_raw)
```
The summary shows that the dataset at least has no missing values, and that that some columns may have some outliers or erronious data. 


### Data Correlation

Now, let's look at the correlation of the columns of data. This can be done in multiple ways, 

First, we need to calculate the correlation matrix for the columns. This can be done using a built-in function of R, **cor()**.
```{r}
# filter the non numeric columns
corr_data <- diamonds_raw[, c(1,5:10)]

# calculate and print the resulting matrix
corr_matrix <- round(cor(corr_data), 2)
corr_matrix
```

Now, we need to **melt** the correlation matrix, using a function from the **reshape2** library. The **melt** function does a similar thing to **pivot_longer**.
```{r}
melted_corr_matrix <- melt(corr_matrix)
head(melted_corr_matrix)
```

Third, we use **ggplot2's geom_tile()** to graph the correlation matrix.
```{r}
ggplot(data = melted_corr_matrix, aes(x=Var1, y=Var2, fill=value)) +
  geom_tile()
```


### Heatmaps of Data

In an effort to make this correlation matrix more readable, we can turn it into a heatmap. A heatmap is helpful, since it uses a different color negative and positive correlation. Also, the heatmap takes out the redundant info from the correlation matrix. We can also take the heatmap and make descisions of what columns to use and discard for the prediction models.

To convert our correlation matrix into a form that is helpful for the heatmap, we must define a couple of helper functions:
```{r}
# get the lower triangle of the matrix
calc_lower_Triangle <- function(corr_mat) {
  corr_mat[upper.tri(corr_mat)] <- NA
  return(corr_mat)
}

# get the upper triangle of the matrix
calc_upper_Triangle <- function(corr_mat) {
  corr_mat[lower.tri(corr_mat)] <- NA
  return(corr_mat)
}
```

After creating our helper functions, we can create a basic and un-ordered heatmap. 
```{r}
# melt the upper triangle of the correlation matrix.
melted_corr_matrix <- melt(calc_upper_Triangle(corr_mat = corr_matrix), na.rm = TRUE)

# create the basic unordered heatmap plot
unordered_heatmap <- ggplot(data = melted_corr_matrix, aes(Var2, Var1, fill = value)) + 
  geom_tile(color = "white") + 
  scale_fill_gradient2(low = "blue", mid = "white", high = "red",       # setup the colors
                       midpoint = 0, limit = c(-1, 1), space = "Lab",   # setup the ranges
                       name="Diamond\nCorrelation") +                   # title of graph
  theme_minimal() + # setup the theme
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) + 
  coord_fixed()
```

<<<<<<< HEAD
Before we plot the graph, it may be a good idea to add labels to each of the squares.
```{r}
unordered_heatmap +
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) + 
  theme( # adding the thematic items
    axis.title.x = element_blank(), axis.title.y = element_blank(),
    panel.grid.major = element_blank(), panel.border = element_blank(),
    panel.background = element_blank(), axis.ticks = element_blank(),
    legend.justification = c(1, 0), legend.position = c(0.55, 0.75), 
    legend.direction = "horizontal") + 
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                               title.position = "top", title.hjust = 0.5))
```

Lastly, for heatmaps we can organize the correlation matrix by highest to lowest correlation. This can help in finding any 'hidden' patterns in the correlation of variables. To do this, we will define another helper function that uses **hclust**; ordering the matrix in a hierarchical clustering order. 
```{r}
# reordering a correlation matrix, using hclust
reorder_matrix <- function(corr_mat) {
  dd <- as.dist((1 - corr_mat) / 2)
  hc <- hclust(dd)
  corr_mat <- corr_mat[hc$order, hc$order]
}
```

Similar to the un-ordered heatmap, we are going to truncate the repeating side of the correlation matrix, as it is not needed. Then the correlation matrix is melted before being plotted.
```{r}
# 1. reordering the correlation matrix
corr_matrix <- reorder_matrix(corr_matrix)

# 2. truncate and melt the matrix
melted_corr_matrix <- melt(calc_upper_Triangle(corr_mat = corr_matrix), na.rm = TRUE)

# 3. create the basic plot
ordered_heatmap <- ggplot(data = melted_corr_matrix, aes(Var2, Var1, fill = value)) + 
  geom_tile(color = "white") + 
  scale_fill_gradient2(low = "blue", mid = "white", high = "red",       # setup the colors
                       midpoint = 0, limit = c(-1, 1), space = "Lab",   # setup the ranges
                       name="Diamond\nCorrelation") +                   # title of graph
  theme_minimal() + # setup the theme
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) + 
  coord_fixed()
```

Again, now we can add value labeling to the squares and move the legend.
```{r}
ordered_heatmap +
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) + 
  theme( # adding the thematic items
    axis.title.x = element_blank(), axis.title.y = element_blank(),
    panel.grid.major = element_blank(), panel.border = element_blank(),
    panel.background = element_blank(), axis.ticks = element_blank(),
    legend.justification = c(1, 0), legend.position = c(0.55, 0.75), 
    legend.direction = "horizontal") + 
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                               title.position = "top", title.hjust = 0.5))  
```
=======
Handling outliers in the dataset
```{r}
#Visualizing outliers in the dataset
boxplot(diamonds_raw$carat)
boxplot(diamonds_raw$depth)
boxplot(diamonds_raw$table)
boxplot(diamonds_raw$x)
boxplot(diamonds_raw$y)
boxplot(diamonds_raw$z)

#Handling outliers
#Carat
the_mean <- mean(as.numeric(diamonds_raw$carat))
the_sd <- sd(as.numeric(diamonds_raw$carat))

diamond_outliers1 <- diamonds_raw |>
  mutate(zscore = (carat - the_mean)/the_sd) |>
  filter(zscore <= 3 & zscore >= -3)

summary(diamond_outliers1) #Lost 439 records which is only 0.81% of the data

#depth
the_mean <- mean(as.numeric(diamonds_raw$depth))
the_sd <- sd(as.numeric(diamonds_raw$depth))

diamond_outliers2 <- diamond_outliers1 |>
  mutate(zscore = (depth - the_mean)/the_sd) |>
  filter(zscore <= 3 & zscore >= -3)

summary(diamond_outliers2) #Lost 663 records which is a cumulative percentage of 2.04% of the total dataset and 1.24% percent of the outlier1 data set

#table
the_mean <- mean(as.numeric(diamonds_raw$table))
the_sd <- sd(as.numeric(diamonds_raw$table))

diamond_outliers3 <- diamond_outliers2 |>
  mutate(zscore = (table - the_mean)/the_sd) |>
  filter(zscore <= 3 & zscore >= -3)

summary(diamond_outliers3) #Lost 264 records which is a cumulative percentage of 2.53% of the total dataset and 0.5% percent of the outlier2 data set

#x
the_mean <- mean(as.numeric(diamonds_raw$x))
the_sd <- sd(as.numeric(diamonds_raw$x))

diamond_outliers4 <- diamond_outliers3 |>
  mutate(zscore = (x - the_mean)/the_sd) |>
  filter(zscore <= 3 & zscore >= -3)

summary(diamond_outliers4) #Lost 6 records which is a cumulative percentage of 2.54% of the total dataset and 0.01% percent of the outlier2 data set

#y
the_mean <- mean(as.numeric(diamonds_raw$y))
the_sd <- sd(as.numeric(diamonds_raw$y))

diamond_outliers5 <- diamond_outliers4 |>
  mutate(zscore = (y - the_mean)/the_sd) |>
  filter(zscore <= 3 & zscore >= -3)

summary(diamond_outliers5) #Lost 2 records which is a cumulative percentage of 2.547% of the total dataset and 0.004% percent of the outlier2 data set

#z
the_mean <- mean(as.numeric(diamonds_raw$z))
the_sd <- sd(as.numeric(diamonds_raw$z))

diamond_outliers6 <- diamond_outliers5 |>
  mutate(zscore = (z - the_mean)/the_sd) |>
  filter(zscore <= 3 & zscore >= -3)

summary(diamond_outliers6) #Lost 14 records which is a cumulative percentage of 2.60% of the total dataset and 0.03% percent of the outlier2 data set
```





>>>>>>> 4553468ab9b5bc99eff4a4614c2d1363bf965291











